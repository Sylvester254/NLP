{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the train and test directories\n",
    "train_dir = \"../IMDb_reviews/test\"\n",
    "test_dir = \"../IMDb_reviews/test\"\n",
    "\n",
    "# Define the columns of the dataframe\n",
    "columns = [\"Review\", \"Label\"]\n",
    "\n",
    "# Load the train set into a dataframe\n",
    "train_data = []\n",
    "for label in [\"pos\", \"neg\"]:\n",
    "    for filename in os.listdir(os.path.join(train_dir, label)):\n",
    "        with open(os.path.join(train_dir, label, filename), \"r\") as f:\n",
    "            text = f.read()\n",
    "            train_data.append([text, label])\n",
    "train_df = pd.DataFrame(train_data, columns=columns)\n",
    "\n",
    "# Load the test set into a dataframe\n",
    "test_data = []\n",
    "for label in [\"pos\", \"neg\"]:\n",
    "    for filename in os.listdir(os.path.join(test_dir, label)):\n",
    "        with open(os.path.join(test_dir, label, filename), \"r\") as f:\n",
    "            text = f.read()\n",
    "            test_data.append([text, label])\n",
    "test_df = pd.DataFrame(test_data, columns=columns)\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample reviews before preprocessing:\n",
      "\n",
      "                                              Review Label\n",
      "0  \"The Dresser\" is a small but absolutely wonder...   pos\n",
      "1  Most of this political thriller presented as a...   pos\n",
      "2  My favorite film this year. Great characters a...   pos\n",
      "3  There was a time when not all animation was Di...   pos\n",
      "4  I always liked listening to Buddy Holly and fe...   pos\n",
      "                                              Review Label\n",
      "0  \"The Dresser\" is a small but absolutely wonder...   pos\n",
      "1  Most of this political thriller presented as a...   pos\n",
      "2  My favorite film this year. Great characters a...   pos\n",
      "3  There was a time when not all animation was Di...   pos\n",
      "4  I always liked listening to Buddy Holly and fe...   pos\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# Apply the preprocessing function to the Review column of the train and test dataframes\u001b[39;00m\n\u001b[1;32m     36\u001b[0m train_df[\u001b[39m\"\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m train_df[\u001b[39m\"\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(preprocess)\n\u001b[0;32m---> 37\u001b[0m test_df[\u001b[39m\"\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_df[\u001b[39m\"\u001b[39;49m\u001b[39mReview\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(preprocess)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Print out the first few reviews after preprocessing\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSample reviews after preprocessing:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     27\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^a-zA-Z\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Tokenize the text and remove stop words\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m tokens \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m nlp(text) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mis_stop]\n\u001b[1;32m     32\u001b[0m \u001b[39m# Join the tokens back into a string\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(tokens)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/pipeline/attributeruler.py:143\u001b[0m, in \u001b[0;36mAttributeRuler.__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    141\u001b[0m error_handler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     matches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatch(doc)\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_annotations(doc, matches)\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/pipeline/attributeruler.py:150\u001b[0m, in \u001b[0;36mAttributeRuler.match\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmatch\u001b[39m(\u001b[39mself\u001b[39m, doc: Doc):\n\u001b[0;32m--> 150\u001b[0m     matches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatcher(doc, allow_missing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, as_spans\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    151\u001b[0m     \u001b[39m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     matches \u001b[39m=\u001b[39m [\n\u001b[1;32m    153\u001b[0m         (\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstrings[m_id]), m_id, s, e) \u001b[39mfor\u001b[39;00m m_id, s, e \u001b[39min\u001b[39;00m matches  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the CSV files into pandas dataframes\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Load the spaCy English language model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Print out the first few reviews before preprocessing\n",
    "print(\"Sample reviews before preprocessing:\\n\")\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "def preprocess(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<[^<]+?>', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub('[^a-zA-Z\\s]+', '', text)\n",
    "    \n",
    "    # Tokenize the text and remove stop words\n",
    "    tokens = [token.text for token in nlp(text) if not token.is_stop]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the preprocessing function to the Review column of the train and test dataframes\n",
    "train_df[\"Review\"] = train_df[\"Review\"].apply(preprocess)\n",
    "test_df[\"Review\"] = test_df[\"Review\"].apply(preprocess)\n",
    "\n",
    "# Print out the first few reviews after preprocessing\n",
    "print(\"\\nSample reviews after preprocessing:\\n\")\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "# Count the number of positive and negative reviews in the preprocessed data\n",
    "pos_count = len(train_data[train_data[\"Label\"]==\"pos\"])\n",
    "neg_count = len(train_data[train_data[\"Label\"]==\"neg\"])\n",
    "print(\"\\nNumber of positive reviews: \", pos_count)\n",
    "print(\"Number of negative reviews: \", neg_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
