{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/business.txt\n",
      "Successfully saved News-Articles/business.txt\n",
      "Successfully saved News-Articles/business.txt\n",
      "Successfully saved News-Articles/technology.txt\n",
      "Successfully saved News-Articles/technology.txt\n",
      "Successfully saved News-Articles/technology.txt\n",
      "Successfully saved News-Articles/technology.txt\n",
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/politics.txt\n",
      "Successfully saved News-Articles/politics.txt\n",
      "Successfully saved News-Articles/politics.txt\n",
      "Successfully saved News-Articles/politics.txt\n",
      "Successfully saved News-Articles/health.txt\n",
      "Successfully saved News-Articles/health.txt\n",
      "Successfully saved News-Articles/health.txt\n",
      "Successfully saved News-Articles/health.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/climate.txt\n",
      "Successfully saved News-Articles/business.txt\n",
      "Successfully saved News-Articles/business.txt\n",
      "Successfully saved News-Articles/business.txt\n",
      "Successfully saved News-Articles/sports.txt\n",
      "Successfully saved News-Articles/politics.txt\n",
      "Successfully saved News-Articles/technology.txt\n",
      "Successfully saved News-Articles/technology.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "# create the directory if it doesn't already exist\n",
    "if not os.path.exists('News-Articles'):\n",
    "    os.makedirs('News-Articles')\n",
    "\n",
    "\n",
    "# Load URLs from JSON file\n",
    "with open('urls.json', 'r') as f:\n",
    "    urls = json.load(f)\n",
    "\n",
    "for url in urls:\n",
    "    url_string = url[\"url\"]\n",
    "    r = requests.get(url_string)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        article = soup.find(\"article\")\n",
    "        # Get the text out of the soup and print it\n",
    "        content = article.get_text()\n",
    "        # print(content)\n",
    "        \n",
    "        # construct the path to the file within the News-Articles directory\n",
    "        filename = os.path.join('News-Articles', url['title'] + '.txt')\n",
    "        with open(filename, 'a') as f:\n",
    "            f.write(content)\n",
    "            f.write('\\n\\n')\n",
    "        print(f'Successfully saved {filename}')\n",
    "    else:\n",
    "        print(f\"Error: {r.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created news_corpus.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Directory where the .txt files are located\n",
    "directory = './News-Articles/'\n",
    "\n",
    "# Create a list to store the rows of the CSV file\n",
    "csv_rows = []\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            content = f.read().replace('\\n', ' ')\n",
    "        \n",
    "        # Get the title from the filename\n",
    "        title = filename.split('.')[0]\n",
    "        \n",
    "        # Append the title and content to the CSV row list\n",
    "        csv_rows.append([title, content])\n",
    "\n",
    "# Write the CSV file\n",
    "with open('news_corpus.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Topic', 'Content'])  # write the header row\n",
    "    writer.writerows(csv_rows)  # write the content rows\n",
    "    print(\"Successfully created news_corpus.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/silver/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Topic                                            Content\n",
      "0       sports  manchester united premier league club owe almo...\n",
      "1       sports  felix jones england recruit exireland fullback...\n",
      "2       sports  premier league tightens ownership rule stop hu...\n",
      "3     business  happening house price could crashpublished hou...\n",
      "4     business  india middle class hit rising cost livingpubli...\n",
      "5     business  bank england heightened alert banking turmoilp...\n",
      "6   technology  elon musk among expert urging halt ai training...\n",
      "7   technology  elon musk twitter bos announces blue tick shak...\n",
      "8   technology  fun apps banned french official phonespublishe...\n",
      "9   technology  google face new multibillion advertising lawsu...\n",
      "10      sports  man city v liverpool danny murphy jurgen klopp...\n",
      "11      sports  premier league relegation nine team danger dro...\n",
      "12    politics  donald trump indictment exus president charged...\n",
      "13    politics  humza yousafs first fmqs hit series disruption...\n",
      "14    politics  margaret ferrier mp face common suspension cov...\n",
      "15    politics  kate forbes snp leadership candidate leaf gove...\n",
      "16      health  blood test may spare cancer patient chemopubli...\n",
      "17      health  uk cosmetic procedure number recover covidpubl...\n",
      "18      health  sniffing body odour tested anxiety therapypubl...\n",
      "19      health  marburg virus dangerous itpublished marchshare...\n",
      "20     climate  climate change england ready impactpublished d...\n",
      "21     climate  swiss court case tie human right climate chang...\n",
      "22     climate  un climate report scientist release survival g...\n",
      "23      sports  premier league domestic flight bbc sport resea...\n",
      "24     climate  climate change really simple guidepublished ma...\n",
      "25     climate  climate change four thing carbon footprintpubl...\n",
      "26     climate  carbon capture fight climate changepublished h...\n",
      "27     climate  guernsey emission lower prepandemic statespubl...\n",
      "28    business  tech helping driverless car see round cornersp...\n",
      "29    business  ukasia trade deal boost uk economy published h...\n",
      "30    business  uk economy lagging behind u germany otherspubl...\n",
      "31      sports  chelsea womenchelsea womenlyon f√©minineslyon f...\n",
      "32    politics  shona robison replaces kate forbes finance sec...\n",
      "33  technology  may thinking digital twin within decadepublish...\n",
      "34  technology  uk rule new ai regulatorpublished day agoshare...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load the news corpus into a Pandas DataFrame\n",
    "df = pd.read_csv('news_articles.csv')\n",
    "\n",
    "# Initialize NLTK components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(Content):\n",
    "    # Remove punctuation\n",
    "    Content = Content.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove digits\n",
    "    Content = re.sub(r'\\d+', '', Content)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(Content.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    # Lemmatize the remaining words\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "    # Rejoin the words into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the news corpus and save into a new CSV file\n",
    "df['Content'] = df['Content'].apply(preprocess_text)\n",
    "df.to_csv('preprocessed_news_corpus.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143\n",
      "Precision: 0.619047619047619\n",
      "Recall: 0.7142857142857143\n",
      "F1-Score: 0.6428571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silver/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "# Load the preprocessed news corpus\n",
    "df = pd.read_csv('preprocessed_news_corpus.csv')\n",
    "\n",
    "# Create a TF-IDF Vectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(2, 3))\n",
    "# vectorizer = TfidfVectorizer(max_df=0.5)\n",
    "vectorizer = TfidfVectorizer(min_df=4)\n",
    "\n",
    "\n",
    "# Vectorize the text data\n",
    "X = vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# Get the labels\n",
    "y = df['Topic']\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SOLVED)\n",
    "Getting an accuracy, precision, recall, and F1-score of 0.0 meanig that the classifier did not correctly predict any of the classes in the test set.\n",
    "I havent figured why since adjusting the parameters of the TF-IDF Vectorizer to improve the quality of the features did not make any difference.\n",
    "Let me try using Bag-of-Words (BoW) model with CountVectorizer instead and see how it turns out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the preprocessed news corpus\n",
    "df = pd.read_csv('preprocessed_news_corpus.csv')\n",
    "\n",
    "# Create a Count Vectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize the text data\n",
    "X = vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# Get the labels\n",
    "y = df['Topic']\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports        7\n",
       "climate       7\n",
       "business      6\n",
       "technology    6\n",
       "politics      5\n",
       "health        4\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed news corpus\n",
    "df = pd.read_csv('preprocessed_news_corpus.csv')\n",
    "\n",
    "# check for class imbalance\n",
    "df['Topic'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SOLVED)\n",
    "This was the issue all along. my corpus is imbalanced. fixable by increasing the size of my dataset by adding more instances of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n",
      "Precision: 0.7857142857142857\n",
      "Recall: 0.5714285714285714\n",
      "F1-Score: 0.6285714285714287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silver/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/silver/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the preprocessed news corpus\n",
    "df = pd.read_csv('preprocessed_news_corpus.csv')\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize the text data\n",
    "X = vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# Get the labels\n",
    "y = df['Topic']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
