{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved sports to CSV\n",
      "Successfully saved sports to CSV\n",
      "Successfully saved sports to CSV\n",
      "Successfully saved business to CSV\n",
      "Successfully saved business to CSV\n",
      "Successfully saved business to CSV\n",
      "Successfully saved technology to CSV\n",
      "Successfully saved technology to CSV\n",
      "Successfully saved technology to CSV\n",
      "Successfully saved technology to CSV\n",
      "Successfully saved sports to CSV\n",
      "Successfully saved sports to CSV\n",
      "Successfully saved politics to CSV\n",
      "Successfully saved politics to CSV\n",
      "Successfully saved politics to CSV\n",
      "Successfully saved politics to CSV\n",
      "Successfully saved health to CSV\n",
      "Successfully saved health to CSV\n",
      "Successfully saved health to CSV\n",
      "Successfully saved health to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved sports to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved climate to CSV\n",
      "Successfully saved business to CSV\n",
      "Successfully saved business to CSV\n",
      "Successfully saved business to CSV\n",
      "Successfully saved sports to CSV\n",
      "Successfully saved politics to CSV\n",
      "Successfully saved technology to CSV\n",
      "Successfully saved technology to CSV\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "# Load URLs from JSON file\n",
    "with open('urls.json', 'r') as f:\n",
    "    urls = json.load(f)\n",
    "\n",
    "# open a CSV file for writing\n",
    "with open('news_articles.csv', mode='w', newline='') as csvfile:\n",
    "    # define the fieldnames for the CSV writer\n",
    "    fieldnames = ['Topic', 'Content']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()  # write the header row to the CSV file\n",
    "\n",
    "    for url in urls:\n",
    "        url_string = url[\"url\"]\n",
    "        r = requests.get(url_string)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "            article = soup.find(\"article\")\n",
    "            # Get the text out of the soup and print it\n",
    "            content = article.get_text()\n",
    "            # print(content)\n",
    "\n",
    "            # write the topic and content to the CSV file\n",
    "            writer.writerow({'Topic': url['title'], 'Content': content})\n",
    "            print(f'Successfully saved {url[\"title\"]} to CSV')\n",
    "        else:\n",
    "            print(f\"Error: {r.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 104]\n",
      "[nltk_data]     Connection reset by peer>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Topic                                            Content\n",
      "0       sports  manchester united premier league club owe almo...\n",
      "1       sports  felix jones england recruit exireland fullback...\n",
      "2       sports  premier league tightens ownership rule stop hu...\n",
      "3     business  happening house price could crashpublished hou...\n",
      "4     business  india middle class hit rising cost livingpubli...\n",
      "5     business  bank england heightened alert banking turmoilp...\n",
      "6   technology  elon musk among expert urging halt ai training...\n",
      "7   technology  elon musk twitter bos announces blue tick shak...\n",
      "8   technology  fun apps banned french official phonespublishe...\n",
      "9   technology  google face new multibillion advertising lawsu...\n",
      "10      sports  man city v liverpool danny murphy jurgen klopp...\n",
      "11      sports  premier league relegation nine team danger dro...\n",
      "12    politics  donald trump indictment exus president charged...\n",
      "13    politics  humza yousafs first fmqs hit series disruption...\n",
      "14    politics  margaret ferrier mp face common suspension cov...\n",
      "15    politics  kate forbes snp leadership candidate leaf gove...\n",
      "16      health  blood test may spare cancer patient chemopubli...\n",
      "17      health  uk cosmetic procedure number recover covidpubl...\n",
      "18      health  sniffing body odour tested anxiety therapypubl...\n",
      "19      health  marburg virus dangerous itpublished marchshare...\n",
      "20     climate  climate change england ready impactpublished d...\n",
      "21     climate  swiss court case tie human right climate chang...\n",
      "22     climate  un climate report scientist release survival g...\n",
      "23      sports  premier league domestic flight bbc sport resea...\n",
      "24     climate  climate change really simple guidepublished ma...\n",
      "25     climate  climate change four thing carbon footprintpubl...\n",
      "26     climate  carbon capture fight climate changepublished h...\n",
      "27     climate  guernsey emission lower prepandemic statespubl...\n",
      "28    business  tech helping driverless car see round cornersp...\n",
      "29    business  ukasia trade deal boost uk economy published h...\n",
      "30    business  uk economy lagging behind u germany otherspubl...\n",
      "31      sports  chelsea womenchelsea womenlyon f√©minineslyon f...\n",
      "32    politics  shona robison replaces kate forbes finance sec...\n",
      "33  technology  may thinking digital twin within decadepublish...\n",
      "34  technology  uk rule new ai regulatorpublished day agoshare...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load the news corpus into a Pandas DataFrame\n",
    "df = pd.read_csv('news_articles.csv')\n",
    "\n",
    "# Initialize NLTK components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(Content):\n",
    "    # Remove punctuation\n",
    "    Content = Content.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove digits\n",
    "    Content = re.sub(r'\\d+', '', Content)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(Content.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    # Lemmatize the remaining words\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "    # Rejoin the words into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the news corpus and save into a new CSV file\n",
    "df['Content'] = df['Content'].apply(preprocess_text)\n",
    "df.to_csv('preprocessed_news_corpus.csv', index=False)\n",
    "print(f'Successfully saved preprocessed data to csv')\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized using TF-IDF Vectorizer and adjusting the parameters to improve the quality of the features.\n",
    "Adjusted min_df=4 meaning any word that appears in the corpus less than 4 times will be excluded from the vocabulary.\n",
    "\n",
    "Training and testing using Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14285714285714285\n",
      "Precision: 1.0\n",
      "Recall: 0.14285714285714285\n",
      "F1-Score: 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "# Load the preprocessed news corpus\n",
    "df = pd.read_csv('preprocessed_news_corpus.csv')\n",
    "\n",
    "# Create a TF-IDF Vectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = TfidfVectorizer(max_df=0.5)\n",
    "# vectorizer = TfidfVectorizer(min_df=4)\n",
    "\n",
    "\n",
    "# Vectorize the text data\n",
    "X = vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# Get the labels\n",
    "y = df['Topic']\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=1))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=1))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead of Tf-idfVectorizer, I've used CountVectorizer. \n",
    "Training and testing with Random Forest classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n",
      "Precision: 0.7857142857142857\n",
      "Recall: 0.5714285714285714\n",
      "F1-Score: 0.6285714285714287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silver/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/silver/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the preprocessed news corpus\n",
    "df = pd.read_csv('preprocessed_news_corpus.csv')\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize the text data\n",
    "X = vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# Get the labels\n",
    "y = df['Topic']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=1))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=1))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
